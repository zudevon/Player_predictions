{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Position of NBA Players\n",
    "### Based on in game stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "shot_df = pd.read_csv(\"./csvData/NBA_Shot_dist - Sheet2.csv\")\n",
    "guard_df = pd.read_csv(\"./csvData/NBA_Shot_dist - guard_list.csv\")\n",
    "forward_df = pd.read_csv(\"./csvData/NBA_Shot_dist - forwards_list.csv\")\n",
    "center_df = pd.read_csv(\"./csvData/NBA_Shot_dist - center_list.csv\")\n",
    "heightWeight_df = pd.read_csv(\"./csvData/playerHeight.csv\")\n",
    "salary_df = pd.read_csv(\"./csvData/playerSalaries.csv\")\n",
    "dribble_df = pd.read_csv(\"./csvData/NBA_Shot_dist - dribble stats.csv\")\n",
    "\n",
    "for col in salary_df.select_dtypes([np.object]):\n",
    "\n",
    "    salary_df[col] = salary_df[col].str.lstrip('$')\n",
    "salary_df = salary_df.replace(regex={',':''})\n",
    "salary_df = salary_df.iloc[:,[1,2]]\n",
    "salary_df.columns = ['name', 'salary']\n",
    "\n",
    "heightWeight_df = heightWeight_df.iloc[:,[0,7,9]]\n",
    "\n",
    "shot_df.columns = ['name', 'team', 'szn', 'type', 'games', \n",
    "              '0to8_make', '8to16_make', '16to24_make', '24plus_make', 'bcMake',\n",
    "              '0to8_att', '8to16_att', '16to24_att', '24plus_att', 'bcatt', \n",
    "              'avg_dist', 'avg_madeDist', 'avg_missDist']\n",
    "\n",
    "gen_df = pd.read_csv(\"./csvData/NBA_Shot_dist - gen_stats.csv\")\n",
    "gen_df = gen_df.iloc[:, [0,19,20,22,23]]\n",
    "gen_df.columns = ['name','reb','ast','stl','blk',]\n",
    "\n",
    "position_df = pd.concat([guard_df, forward_df, center_df])\n",
    "position_df = position_df.groupby(['name'], as_index = False).sum()\n",
    "\n",
    "dribble_df = dribble_df.iloc[:,[0,11,14,15]]\n",
    "dribble_df.columns = ['name', 'avgDrib', 'post', 'paint']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(heightWeight_df, shot_df, how='inner')\n",
    "df = pd.merge(df,gen_df, how='inner')\n",
    "df = pd.merge(df,dribble_df, how='inner')\n",
    "df = pd.merge(df,salary_df, how='inner')\n",
    "df = pd.merge(df, position_df, how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deleting Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['0to8_att']\n",
    "del df['8to16_att']\n",
    "del df['16to24_att']\n",
    "del df['24plus_att']\n",
    "del df['bcatt']\n",
    "del df['bcMake']\n",
    "del df['avg_missDist']\n",
    "del df['avg_dist']\n",
    "del df['team']\n",
    "del df['szn']\n",
    "del df['type']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating X and y - Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = df.iloc[:, 1:16]\n",
    "x['heightMeters'] = x['heightMeters']**3\n",
    "x['weightKilograms'] = x['weightKilograms']**3\n",
    "x['avg_madeDist'] = x['avg_madeDist']**3\n",
    "x['reb'] = x['reb']**2\n",
    "x['avgDrib'] = x['avgDrib']**2\n",
    "x['games'] = (x['games'])/82 \n",
    "\n",
    "y = df.iloc[:, 17:20]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7870370370370371  -- Accuracy with Random Forests\n",
      "\n",
      "-------------- Importances per column with RF\n",
      "[0.22546283 0.13651019 0.02244055 0.03101973 0.02553679 0.02328163\n",
      " 0.03677946 0.07921836 0.04015079 0.0369766  0.02465256 0.03046037\n",
      " 0.13685973 0.05234782 0.09830259] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "\"\"\" RANDOM FOREST PREDICTION \"\"\"\n",
    "\n",
    "# X, y = make_classification(n_samples=100, n_features=5, n_informative=5, n_redundant=0, random_state=0, shuffle=False)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=120, max_depth=15, random_state=0)\n",
    "\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "\n",
    "print(metrics.accuracy_score(y_test, y_pred), \" -- Accuracy with Random Forests\\n\")\n",
    "\n",
    "print(\"-------------- Importances per column with RF\")\n",
    "\n",
    "print((clf.feature_importances_), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Y's up\n",
    "* y1 = guard\n",
    "* y2 = forward\n",
    "* y3 = center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = y.iloc[:,0]\n",
    "x_train, x_test, y1_train, y1_test = train_test_split(x, y1, test_size=.3)\n",
    "#y2 = y.iloc[:,1]\n",
    "#X_train, X_test, y2_train, y2_test = train_test_split(X, y2, test_size=.3)\n",
    "#y3 = y.iloc[:,2]\n",
    "#X_train, X_test, y3_train, y3_test = train_test_split(X, y3, test_size=.3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9351851851851852  -- Accuracy with Random Forests\n",
      "\n",
      "-------------- Importances per column with RF\n",
      "[0.24856658 0.18127305 0.01680873 0.0139656  0.01547802 0.01475307\n",
      " 0.02021905 0.04732959 0.02550425 0.04944857 0.019971   0.0350338\n",
      " 0.17788939 0.05006403 0.08369526] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" RANDOM FOREST PREDICTION \"\"\"\n",
    "\n",
    "# X, y = make_classification(n_samples=100, n_features=5, n_informative=5, n_redundant=0, random_state=0, shuffle=False)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=120, max_depth=15, random_state=0)\n",
    "\n",
    "clf.fit(x_train, y1_train)\n",
    "\n",
    "y1_pred = clf.predict(x_test)\n",
    "\n",
    "\n",
    "print(metrics.accuracy_score(y1_test, y1_pred), \" -- Accuracy with Random Forests\\n\")\n",
    "\n",
    "print(\"-------------- Importances per column with RF\")\n",
    "\n",
    "print((clf.feature_importances_), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using KMeans to determine how many groups to make\n",
    "* Make 20 models\n",
    "* Group by group number\n",
    "* sum by position\n",
    "* get score of model\n",
    "* check w salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import numpy as np\n",
    "\n",
    "# Use silhouette score to find optimal number of clusters to segment the data\n",
    "num_clusters = np.arange(2,10)\n",
    "results = {}\n",
    "for size in num_clusters:\n",
    "    model = KMeans(n_clusters = size).fit(x)\n",
    "    predictions = model.predict(x)\n",
    "    results[size] = silhouette_score(x, predictions)\n",
    "\n",
    "best_size = max(results, key=results.get)\n",
    "best_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters= 2)\n",
    "kmeans = kmeans.fit(x)\n",
    "\n",
    "labels = kmeans.predict(x)\n",
    "centroids = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/denvercomp/.pyenv/versions/3.6.2/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/denvercomp/.pyenv/versions/3.6.2/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "x['group'] = labels\n",
    "\n",
    "df[\"salary\"] = round(df.salary.astype(pd.np.number))\n",
    "salaries = df.iloc[:,16].values\n",
    "x = df[[\"name\", \"guard\", \"forward\", \"center\"]]\n",
    "x['salary'] = salaries / 1e6\n",
    "x[\"group\"] = labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>guard</th>\n",
       "      <th>forward</th>\n",
       "      <th>center</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>158</td>\n",
       "      <td>84</td>\n",
       "      <td>6</td>\n",
       "      <td>7.499110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>95</td>\n",
       "      <td>83</td>\n",
       "      <td>9.115923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   group  guard  forward  center    salary\n",
       "0      0    158       84       6  7.499110\n",
       "1      1      8       95      83  9.115923"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_groups = x.groupby('group', as_index=False)['guard', 'forward', 'center'].sum()\n",
    "df_group_salary = x.groupby('group', as_index=False)['salary'].mean()\n",
    "df_groups = pd.merge(df_groups, df_group_salary, how='inner')\n",
    "df_groups"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
