{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Position of NBA Players\n",
    "### Based on in game stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "shot_df = pd.read_csv(\"./csvData/NBA_Shot_dist - Sheet2.csv\")\n",
    "guard_df = pd.read_csv(\"./csvData/NBA_Shot_dist - guard_list.csv\")\n",
    "forward_df = pd.read_csv(\"./csvData/NBA_Shot_dist - forwards_list.csv\")\n",
    "center_df = pd.read_csv(\"./csvData/NBA_Shot_dist - center_list.csv\")\n",
    "heightWeight_df = pd.read_csv(\"./csvData/playerHeight.csv\")\n",
    "\n",
    "heightWeight_df = heightWeight_df.iloc[:,[0,7,9]]\n",
    "\n",
    "shot_df.columns = ['name', 'team', 'szn', 'type', 'games', \n",
    "              '0to8_make', '8to16_make', '16to24_make', '24plus_make', 'bcMake',\n",
    "              '0to8_att', '8to16_att', '16to24_att', '24plus_att', 'bcatt', \n",
    "              'avg_dist', 'avg_madeDist', 'avg_missDist']\n",
    "\n",
    "gen_df = pd.read_csv(\"./csvData/NBA_Shot_dist - gen_stats.csv\")\n",
    "gen_df = gen_df.iloc[:, [0,19,20,22,23]]\n",
    "gen_df.columns = ['name','reb','ast','stl','blk',]\n",
    "\n",
    "position_df = pd.concat([guard_df, forward_df, center_df])\n",
    "position_df = position_df.groupby(['name'], as_index = False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(heightWeight_df, shot_df, how='inner')\n",
    "df = pd.merge(df,gen_df, how='inner')\n",
    "df = pd.merge(df, position_df, how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deleting Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['0to8_att']\n",
    "del df['8to16_att']\n",
    "del df['16to24_att']\n",
    "del df['24plus_att']\n",
    "del df['bcatt']\n",
    "del df['bcMake']\n",
    "del df['avg_missDist']\n",
    "del df['avg_dist']\n",
    "del df['team']\n",
    "del df['szn']\n",
    "del df['type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ### Tuning and Normalizing\n",
    "   * adding avg_madeDist^2 col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating X and y - Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.iloc[:, 1:13]\n",
    "\n",
    "y = df.iloc[:, 13:16]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7368421052631579  -- Accuracy with Random Forests\n",
      "\n",
      "-------------- Importances per column with RF\n",
      "[0.32199377 0.18964395 0.02764229 0.04623753 0.03016824 0.03600212\n",
      " 0.04269972 0.09406097 0.0576071  0.064818   0.03183799 0.05728833] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "\"\"\" RANDOM FOREST PREDICTION \"\"\"\n",
    "\n",
    "# X, y = make_classification(n_samples=100, n_features=5, n_informative=5, n_redundant=0, random_state=0, shuffle=False)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=120, max_depth=15, random_state=0)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "print(metrics.accuracy_score(y_test, y_pred), \" -- Accuracy with Random Forests\\n\")\n",
    "\n",
    "print(\"-------------- Importances per column with RF\")\n",
    "\n",
    "print((clf.feature_importances_), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Y's up\n",
    "* y1 = guard\n",
    "* y2 = forward\n",
    "* y3 = center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = y.iloc[:,0]\n",
    "X_train, X_test, y1_train, y1_test = train_test_split(X, y1, test_size=.3)\n",
    "#y2 = y.iloc[:,1]\n",
    "#X_train, X_test, y2_train, y2_test = train_test_split(X, y2, test_size=.3)\n",
    "#y3 = y.iloc[:,2]\n",
    "#X_train, X_test, y3_train, y3_test = train_test_split(X, y3, test_size=.3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9210526315789473  -- Accuracy with Random Forests\n",
      "\n",
      "-------------- Importances per column with RF\n",
      "[0.37431235 0.22350299 0.01632842 0.03647583 0.017066   0.01972231\n",
      " 0.0214974  0.04985657 0.09017561 0.0745348  0.02358435 0.05294335] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" RANDOM FOREST PREDICTION \"\"\"\n",
    "\n",
    "# X, y = make_classification(n_samples=100, n_features=5, n_informative=5, n_redundant=0, random_state=0, shuffle=False)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=120, max_depth=15, random_state=0)\n",
    "\n",
    "clf.fit(X_train, y1_train)\n",
    "\n",
    "y1_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "print(metrics.accuracy_score(y1_test, y1_pred), \" -- Accuracy with Random Forests\\n\")\n",
    "\n",
    "print(\"-------------- Importances per column with RF\")\n",
    "\n",
    "print((clf.feature_importances_), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using KMeans to determine how many groups to make\n",
    "* Make 20 models\n",
    "* Group by group number\n",
    "* sum by position\n",
    "* get score of model\n",
    "* check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import numpy as np\n",
    "\n",
    "# Use silhouette score to find optimal number of clusters to segment the data\n",
    "num_clusters = np.arange(2,10)\n",
    "results = {}\n",
    "for size in num_clusters:\n",
    "    model = KMeans(n_clusters = size).fit(X)\n",
    "    predictions = model.predict(X)\n",
    "    results[size] = silhouette_score(X, predictions)\n",
    "\n",
    "best_size = max(results, key=results.get)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
